### 서포트($N_S$) 및 쿼리($N_Q$) 샘플 수 최적화 방안

`Validation task created from unseen months with 5 support and 10 query samples.`

서포트 셋의 크기 $N_S$(`K_SHOT`)와 쿼리 셋의 크기 $N_Q$(`K_QUERY`)는 메타-러닝의 성능과 안정성에 큰 영향을 미치는 중요한 하이퍼파라미터입니다. 이들을 최적화하는 것은 이론과 실험의 균형이 필요한 문제입니다.

#### 가. 개념적 이해와 트레이드오프

*   **서포트 셋 크기 ($N_S$)**:
    *   **$N_S$가 클수록**: 내부 루프에서 태스크에 대해 더 많은 정보를 가지고 적응할 수 있습니다. 이는 사후 분포 $q(\phi|\lambda)$를 더 정확하게 추정하게 하여, 쿼리 셋에 대한 성능을 높일 수 있습니다.
    *   **$N_S$가 작을수록**: 더 적은 데이터로 적응하는 법을 배우므로, 실제 테스트 환경에서 데이터가 매우 적을 때(진정한 few-shot learning) 더 강건한 성능을 보일 수 있습니다. 또한, 계산 비용이 줄어듭니다.
    *   **트레이드오프**: $N_S$가 너무 크면 모델이 '적응'하는 법 대신 '일반적인 학습'을 해버릴 수 있고, 너무 작으면 적응에 필요한 정보가 부족하여 성능이 저하될 수 있습니다.

*   **쿼리 셋 크기 ($N_Q$)**:
    *   **$N_Q$가 클수록**: 외부 루프에서 계산되는 메타-그래디언트($g_\theta$)가 더 안정적입니다. 소수의 쿼리 샘플에 의한 노이즈(noise)의 영향을 줄여, 메타-파라미터 $\theta$가 더 안정적으로 수렴하도록 돕습니다.
    *   **$N_Q$가 작을수록**: 계산 비용이 줄어듭니다.
    *   **트레이드오프**: $N_Q$가 너무 작으면 메타-그래디언트의 분산이 커져 학습이 불안정해지고, 너무 크면 학습 속도가 느려집니다.

#### 나. 수식적 접근 및 최적화 방안

$N_S$와 $N_Q$를 최적화하는 문제는 통계적 학습 이론, 특히 **편향-분산 트레이드오프(Bias-Variance Tradeoff)**와 관련이 깊습니다.

메타-러닝의 최종 목표는 테스트 태스크 $\mathcal{T}_{test}$에 대한 기대 손실 $\mathbb{E}_{\mathcal{T}_{test}}[\mathcal{L}_{outer}(\theta^*, \mathcal{T}_{test})]$를 최소화하는 최적의 메타-파라미터 $\theta^*$를 찾는 것입니다. 이 손실은 다음과 같이 분해될 수 있습니다.

$$
\text{Expected Test Error} \approx \underbrace{\text{Bias}(\hat{\theta})}_{\text{얼마나 정답에 가까운가}} + \underbrace{\text{Var}(\hat{\theta})}_{\text{얼마나 안정적인가}}
$$

*   **$N_S$의 영향**: $N_S$는 주로 **편향(Bias)**에 영향을 줍니다. $N_S$가 증가하면 내부 루프에서 더 정확한 적응이 가능해져, 쿼리 셋 예측의 편향이 감소하는 경향이 있습니다.

$$
\text{Bias} \propto \frac{1}{N_S} \quad (\text{단순화된 가정})
$$

*   **$N_Q$의 영향**: $N_Q$는 주로 **분산(Variance)**에 영향을 줍니다. $N_Q$가 증가하면 메타-그래디언트의 추정치가 안정화되어, 최종적으로 학습된 메타-파라미터 $\hat{\theta}$의 분산이 감소합니다.

$$
\text{Var}(\nabla_\theta \mathcal{L}_{outer}) \propto \frac{1}{N_Q} \implies \text{Var}(\hat{\theta}) \propto \frac{1}{N_{tasks} \cdot N_Q}
$$

**최적화 전략:**

이론적으로 최적의 $N_S, N_Q$를 찾는 닫힌 형태의 해(closed-form solution)는 없습니다. 따라서 다음과 같은 실험적 접근이 필요합니다.

1.  **그리드 탐색 (Grid Search)**:
    *   $N_S$와 $N_Q$에 대한 후보 값들의 조합을 설정합니다. (예: $N_S \in \{1, 5, 10\}$, $N_Q \in \{5, 10, 20\}$)
    *   각 조합 $(N_S, N_Q)$에 대해 메타-훈련을 수행하고, **고정된 검증 태스크(validation task)에서의 최종 손실**을 비교합니다.
    *   가장 낮은 검증 손실을 보인 조합을 최적의 값으로 선택합니다.

2.  **경험적 가이드라인**:
    *   **$N_Q > N_S$**: 일반적으로 메타-그래디언트의 안정을 위해 쿼리 셋을 서포트 셋보다 크거나 같게 설정하는 것이 좋습니다. 현재 설정인 `5 support`, `10 query`는 이 가이드라인을 잘 따르고 있습니다.
    *   **실제 테스트 환경 모방**: 최종적으로 모델이 배포될 환경에서 예상되는 샘플 수를 고려하여 $N_S$를 설정하는 것이 가장 좋습니다. 예를 들어, 새로운 지역에 모델을 적용할 때 약 10개의 데이터 샘플을 사용할 수 있다면, 훈련 시에도 $N_S=10$으로 설정하여 그 환경에 맞는 적응 능력을 학습시키는 것이 효과적입니다.
    *   **계산 자원 고려**: GPU 메모리와 학습 시간을 고려하여 $N_S$와 $N_Q$의 상한을 정해야 합니다.
